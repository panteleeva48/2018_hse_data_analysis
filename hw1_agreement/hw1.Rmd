---
title: "hw1"
author: "Ira Panteleeva"
date: "06 02 2018"
output: html_document
---

### 1.1
#### Скачайте датасет hw1_1_zilo_class.csv (см. описание выше). Получите тиббл содержащий два столбца: stimulus_source и количество уникальных слов в датасете (n).
```{r}
library(tidyverse)
df <- read.csv("https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/panteleeva48/hw1_agreement/hw1_1_zilo_class.csv", encoding = 'UTF-8')
df %>%
  distinct(stimulus_source, translation_ru) %>%
  count(stimulus_source) -> df1
head(df1)
```
### 1.2
#### Преобразуйте датасет hw1_1_zilo_class.csv. Посчитайте процент полного согласия всех спикеров.
```{r}
library(irr)
df %>% 
  select(s_id, stimulus, translation_ru, stimulus_source, class) %>% 
  spread(key = s_id, value = class) ->
  zilo_classes_short
agree(zilo_classes_short[,-c(1:3)])
```
### 1.3
#### Из преобразованным датасета hw1_1_zilo_class.csv выберите спикеров с номером 7 и 11 и посчитайте для них каппу Коэна.
```{r}
zilo_classes_2s <- zilo_classes_short[,c(7, 11)]
agree(zilo_classes_2s)
table(zilo_classes_2s)
p_o <- (42+36)/(42+36+5+6)
p_e <- ((42+5)*(42+6)+(36+5)*(36+6))/(42+36+5+6)^2
coehns_kappa <- (p_o - p_e)/(1 - p_e)
coehns_kappa
```
### 1.4
#### Посчитайте каппу Фляйса для всех спикеров преобразованного датасета hw1_1_zilo_class.csv.
```{r}
kappam.fleiss(zilo_classes_short[,-c(1:3)])
```
### 1.5
#### Представим, что Вы пишите статью, напишите короткий абзац, который бы обобщал результаты, полученные в предыдущих заданиях.
##### В исследовании проверялось распределение заимствованной и исконной лексики по классами в зиловском диалекте андийского языка. Мера согласия между информантами рассчитывалась с помощью процента полного согласия, каппы Коэна и каппы Фляйса. По проценту полного согласия выяснилось, что в 73% случаях все информанты идентичны в своих суждениях. Для случайно выбранных двух спикеров результат каппы Коэна является 0.75, что означает высокую степень согласованности между спикерами [Landis, Koch 1977]. Данный вывод подверждается каппой Фляйса, которая составляет 0.84.
### 2.1
#### Скачайте датасет hw1_2_verbs.csv (см. описание выше). Посчитайте количество участников в датасете (в ответ выведите тибл с переменной n).
```{r}
df_2 <- read.csv("https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/panteleeva48/hw1_agreement/hw1_2_verbs.csv", encoding = 'UTF-8')
as_tibble(df_2) %>%
  summarise(n = n_distinct(SubjectCode)) -> df2
head(df2)
```
### 2.2
#### Посчитайте среднюю оценку глаголов разного типа для каждого пола в датасете (в ответ выведите тибл с переменными WordType, Gender и mean).
```{r}
as_tibble(df_2)%>%
  group_by(WordType, Gender)%>%
  summarise(mean = mean(GivenScore)) -> score_mean
head(score_mean)
```
### 2.3
#### Преобразуйте датасет в короткий формат и удалите строки, в которых есть пропущенные значения (у меня вышел тибл 59 x 124). Посчитайте процент полного согласия.
```{r}
as_tibble(df_2) %>% 
  select(SubjectCode, Stimulus, WordType, Prefix, GivenScore) %>% 
  spread(key = SubjectCode, value = GivenScore) ->
  df_2_short
df_2_short <- na.omit (df_2_short)
agree(df_2_short[,-c(1:3)])
```
### 2.4
#### Посчитайте каппу Фляйса для преобразованного датасета.
```{r}
kappam.fleiss(df_2_short[,-c(1:3)])
```
### 2.5
#### Посчитайте ICC для преобразованного датасета.
```{r}
icc(df_2_short[,-c(1:3)], model = "twoway", type = "agreement")
```
### 2.6
#### Создайте тибл, содержащий минимальное (min) и максимальное (max) значение попарной корреляции Кендала ответов всех участников эксперимента со словами (т. е. корреляция ответов АА и AB, AA и AC и т. д.). В преобразовании матрицы, пораждаемой функцией cor() мне очень помогла функция as.table().
```{r}
matrix <- as.table(cor(df_2_short[,-c(1:3)], method = "kendall"))
mmc <- tibble(first=rownames(matrix)[row(matrix)[upper.tri(matrix)]], 
              second=colnames(matrix)[col(matrix)[upper.tri(matrix)]],
              correlation = matrix[upper.tri(matrix)])
tibble(max = max(mmc$correlation), min = min(mmc$correlation))
```